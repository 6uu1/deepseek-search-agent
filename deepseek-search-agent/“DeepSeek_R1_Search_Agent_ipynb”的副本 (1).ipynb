{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6UkhtoS_6wr"
      },
      "source": [
        "# Deepseek With Jina Tools\n",
        "\n",
        "In this notebook we equip DeepSeek R1 for deep search, using Jina AI's APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jFWdbnp_6ws"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "In the Google Colab sidebar [secrets section](https://labs.thinktecture.com/secrets-in-google-colab-the-new-way-to-protect-api-keys/), set up your `JINA_API_KEY` (get a free one [here](ttps://jina.ai)) and `OPENROUTER_API_KEY` (get a free one [here](https://openrouter.ai/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT2j6of3_6wt"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"JINA_API_KEY\"] = userdata.get('JINA_API_KEY')\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get('OPENROUTER_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mU5slbFx__bW"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-text-splitters\n",
        "!pip install -q jinja2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBkSXmpYZVII"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "from typing import (\n",
        "    Any,\n",
        "    Callable,\n",
        "    Dict,\n",
        "    Iterator,\n",
        "    List,\n",
        "    Optional,\n",
        "    TypedDict,\n",
        ")\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "import aiohttp\n",
        "from IPython.display import clear_output\n",
        "from jinja2 import BaseLoader, Environment\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mMsGc4pN43E"
      },
      "source": [
        "# Helper classes and functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FO2HHDqDeyp"
      },
      "source": [
        "## Processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXBuEHI5DImx"
      },
      "outputs": [],
      "source": [
        "def extract_json_values(text: str) -> Iterator[Any]:\n",
        "    decoder = json.JSONDecoder()\n",
        "\n",
        "    def next_json_position(pos: int) -> int | None:\n",
        "        matches = [p for p in (text.find(c, pos) for c in \"{[\") if p != -1]\n",
        "        return min(matches) if matches else None\n",
        "\n",
        "    pos = 0\n",
        "    while (next_pos := next_json_position(pos)) is not None:\n",
        "        try:\n",
        "            result, index = decoder.raw_decode(text[next_pos:])\n",
        "            yield result\n",
        "            pos = next_pos + index\n",
        "        except json.JSONDecodeError:\n",
        "            pos = next_pos + 1\n",
        "\n",
        "\n",
        "def extract_largest_json(text: str) -> dict:\n",
        "    try:\n",
        "        json_values = list(extract_json_values(text))\n",
        "        if not json_values:\n",
        "            raise ValueError(\"No JSON found in response\")\n",
        "        return max(json_values, key=lambda x: len(json.dumps(x)))\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to extract JSON: {str(e)}\\nText: {text}\")\n",
        "\n",
        "\n",
        "def segment_rc(text: str, chunk_size=1000, chunk_overlap=500) -> List[str]:\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "\n",
        "    texts = text_splitter.split_text(text)\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWxkwIpGRp_s"
      },
      "outputs": [],
      "source": [
        "async def rerank(\n",
        "    text: str,\n",
        "    query: str,\n",
        "    top_docs: int = 5,\n",
        "    split_fn: Callable[[str], list[str]] | None = None,\n",
        "    merge_fn: Callable[[List[str]], str] | None = None,\n",
        ") -> str:\n",
        "    url = f\"https://api.jina.ai/v1/rerank\"\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    if api_key := os.getenv(\"JINA_API_KEY\"):\n",
        "        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
        "\n",
        "    if not split_fn:\n",
        "        split_fn = segment_rc\n",
        "\n",
        "    if not merge_fn:\n",
        "        merge_fn = lambda t: \"\\n\".join(t)\n",
        "\n",
        "    chunks = split_fn(text)\n",
        "\n",
        "    data = {\n",
        "        \"model\": \"jina-reranker-v2-base-multilingual\",\n",
        "        \"query\": query,\n",
        "        \"top_n\": top_docs,\n",
        "        \"documents\": chunks,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            async with session.post(url, headers=headers, json=data) as response:\n",
        "                if response.status != 200:\n",
        "                    print(f\"Failed to fetch {url}: {response.status}\")\n",
        "                    raise Exception(f\"Failed to fetch {url}: {response.status}\")\n",
        "\n",
        "                data = await response.json()\n",
        "                results = [result[\"document\"][\"text\"] for result in data[\"results\"]]\n",
        "                merged_text = merge_fn(results)\n",
        "                return merged_text\n",
        "\n",
        "    except Exception as e:\n",
        "        raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kDw4rQ5Dl1g"
      },
      "source": [
        "## Tools\n",
        "Search and Scrap tool classes using Jina APIs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxGw0TytZb6V"
      },
      "outputs": [],
      "source": [
        "class ScrapTool:\n",
        "    def __init__(self, gather_links: bool = True) -> None:\n",
        "        self.gather_links = gather_links\n",
        "\n",
        "    async def __call__(self, input: str, context: str | None) -> str:\n",
        "        result = await self.scrap_webpage(input, context)\n",
        "        return result\n",
        "\n",
        "    async def scrap_webpage(self, url: str, context: str | None) -> str:\n",
        "        url = f\"https://r.jina.ai/{url}\"\n",
        "\n",
        "        headers = {\"X-Retain-Images\": \"none\", \"X-With-Links-Summary\": \"true\"}\n",
        "\n",
        "        if api_key := os.getenv(\"JINA_API_KEY\"):\n",
        "            headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
        "\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                async with session.get(url, headers=headers) as response:\n",
        "                    if response.status != 200:\n",
        "                        print(f\"Failed to fetch {url}: {response.status}\")\n",
        "                        raise Exception(f\"Failed to fetch {url}: {response.status}\")\n",
        "                    result = await response.text()\n",
        "\n",
        "            if context is not None:\n",
        "                split_fn = lambda t: segment_rc(t)\n",
        "                merge_fn = lambda t: \"\\n\".join(t)\n",
        "\n",
        "                reranked = await rerank(\n",
        "                    result, context, split_fn=split_fn, merge_fn=merge_fn\n",
        "                )\n",
        "\n",
        "                result = reranked\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJXoHWzkDcy8"
      },
      "outputs": [],
      "source": [
        "class SearchResult(TypedDict):\n",
        "    url: str\n",
        "    title: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "class SearchTool:\n",
        "    def __init__(self, timeout: int = 60 * 5) -> None:\n",
        "        self.timeout = timeout\n",
        "\n",
        "    async def __call__(self, input: str, *args) -> str:\n",
        "        results = await self.search(input)\n",
        "        formatted_results = self._format_results(results)\n",
        "        return formatted_results\n",
        "\n",
        "    async def search(self, query: str) -> List[SearchResult]:\n",
        "        url = f\"https://s.jina.ai/{quote_plus(query)}\"\n",
        "\n",
        "        headers = {\n",
        "            \"Accept\": \"application/json\",\n",
        "            \"X-Retain-Images\": \"none\",\n",
        "            \"X-No-Cache\": \"true\",\n",
        "        }\n",
        "\n",
        "        if api_key := os.getenv(\"JINA_API_KEY\"):\n",
        "            headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
        "\n",
        "        try:\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                async with session.get(\n",
        "                    url, headers=headers, timeout=self.timeout\n",
        "                ) as response:\n",
        "                    if response.status != 200:\n",
        "                        print(f\"Failed to fetch {url}: {response.status}\")\n",
        "                        raise Exception(f\"Failed to fetch {url}: {response.status}\")\n",
        "\n",
        "                    json_response = await response.json()\n",
        "\n",
        "            results = [\n",
        "                SearchResult(\n",
        "                    url=result[\"url\"],\n",
        "                    title=result[\"title\"],\n",
        "                    description=result[\"description\"],\n",
        "                )\n",
        "                for result in json_response[\"data\"]\n",
        "            ]\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            raise e\n",
        "\n",
        "    def _format_results(self, results: List[SearchResult]) -> str:\n",
        "        formatted_results = []\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            formatted_results.extend(\n",
        "                [\n",
        "                    f\"Title: {result['title']}\",\n",
        "                    f\"URL Source: {result['url']}\",\n",
        "                    f\"Description: {result['description']}\",\n",
        "                    \"\",\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        return \"\\n\".join(formatted_results).rstrip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8R_JkzcDnvv"
      },
      "source": [
        "## Model API utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh1vvIIVypeC"
      },
      "outputs": [],
      "source": [
        "class OpenRouterModel:\n",
        "    def __init__(self, model_name=\"deepseek/deepseek-r1:free\", api_key=None, base_url=\"https://openrouter.ai/api/v1/chat/completions\"):\n",
        "        self.model_name = model_name\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "\n",
        "    def _get_headers(self):\n",
        "        return {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "\n",
        "    def _build_payload(self, messages, reasoning_effort=\"low\"):\n",
        "        return {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": messages,\n",
        "            \"reasoning\": {\"effort\": reasoning_effort},\n",
        "        }\n",
        "\n",
        "    async def __call__(self, message: str, reasoning_effort=\"low\"):\n",
        "        messages = [{\"role\": \"user\", \"content\": message}]\n",
        "        headers = self._get_headers()\n",
        "        payload = self._build_payload(messages, reasoning_effort)\n",
        "\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            async with session.post(\n",
        "                self.base_url, headers=headers, json=payload\n",
        "            ) as response:\n",
        "                if response.status != 200:\n",
        "                    error_text = await response.text()\n",
        "                    raise Exception(\n",
        "                        f\"API request failed with status {response.status}: {error_text}\"\n",
        "                    )\n",
        "                response = await response.json()\n",
        "\n",
        "                think_content = response[\"choices\"][0][\"message\"][\"reasoning\"]\n",
        "                content = (\n",
        "                    think_content + \"\\n\" + response[\"choices\"][0][\"message\"][\"content\"]\n",
        "                )\n",
        "                return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvHbBNg3sYlq"
      },
      "outputs": [],
      "source": [
        "model = OpenRouterModel(api_key=os.environ[\"OPENROUTER_API_KEY\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FuLIMD4DpNo"
      },
      "source": [
        "## Prompt utility class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byk_rI1Man5v"
      },
      "outputs": [],
      "source": [
        "class Prompt:\n",
        "    def __init__(self, template: str) -> None:\n",
        "        self.template = template\n",
        "        self.env = Environment(loader=BaseLoader())\n",
        "\n",
        "    def __call__(self, **variables) -> str:\n",
        "        prompt_template = self.env.from_string(self.template)\n",
        "        prompt = prompt_template.render(**variables)\n",
        "        prompt = prompt.strip()\n",
        "        return prompt\n",
        "\n",
        "    async def run(\n",
        "        self,\n",
        "        prompt_variables: Dict[str, Any] = {},\n",
        "        generation_args: Dict[str, Any] = {},\n",
        "    ) -> str:\n",
        "        global model\n",
        "        prompt = self(**prompt_variables)\n",
        "        print(f\"\\nPrompt:\\n{prompt}\")\n",
        "        try:\n",
        "            result = await model(prompt)\n",
        "            print(f\"\\nResult:\\n{result}\")\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPZCFAUvOBtH"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD6GGvmvOAQp"
      },
      "outputs": [],
      "source": [
        "class Workspace:\n",
        "    def __init__(self):\n",
        "        self.state = {\"status\": \"IN_PROGRESS\", \"blocks\": {}, \"answer\": None}\n",
        "\n",
        "    def to_string(self):\n",
        "        \"\"\"\n",
        "        Converts the workspace state to a formatted string representation.\n",
        "\n",
        "        Returns:\n",
        "            str: A string representation of the workspace state\n",
        "        \"\"\"\n",
        "        result = f\"Status: {self.state['status']}\\n\"\n",
        "        result += \"Memory: \\n\"\n",
        "\n",
        "        if not self.state[\"blocks\"]:\n",
        "            result += \"... no memory blocks ...\\n\"\n",
        "        else:\n",
        "            for block_id, content in self.state[\"blocks\"].items():\n",
        "                result += f\"<{block_id}>{content}</{block_id}>\\n\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _generate_unique_block_id(self):\n",
        "        \"\"\"\n",
        "        Generate a unique block ID in the format abc-123.\n",
        "\n",
        "        Returns:\n",
        "            str: A unique ID consisting of 3 lowercase letters, a hyphen, and 3 digits\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            # Generate random ID in abc-123 format\n",
        "            letters = \"\".join(random.choices(string.ascii_lowercase, k=3))\n",
        "            digits = \"\".join(random.choices(string.digits, k=3))\n",
        "            new_id = f\"{letters}-{digits}\"\n",
        "\n",
        "            # Return ID if it's unique\n",
        "            if new_id not in self.state[\"blocks\"]:\n",
        "                return new_id\n",
        "\n",
        "    def update_blocks(\n",
        "        self, status: str, blocks: List[Dict], answer: Optional[str] = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Updates the workspace state with new status, blocks, and answer.\n",
        "\n",
        "        Args:\n",
        "            status (str): New status (\"IN_PROGRESS\" or \"DONE\")\n",
        "            blocks (List[Dict]): List of block operations to apply\n",
        "                Each dict should have:\n",
        "                - \"operation\": \"add\" or \"delete\"\n",
        "                - \"content\": content to add (for \"add\" operation)\n",
        "                - \"id\": block id to delete (for \"delete\" operation)\n",
        "            answer (Optional[str]): Final answer when status is \"DONE\"\n",
        "        \"\"\"\n",
        "        # Update status\n",
        "        self.state[\"status\"] = status\n",
        "\n",
        "        # Update blocks based on operations\n",
        "        for block_op in blocks:\n",
        "            operation = block_op.get(\"operation\")\n",
        "\n",
        "            if operation == \"add\":\n",
        "                # Generate a unique block ID using helper function\n",
        "                new_id = self._generate_unique_block_id()\n",
        "                self.state[\"blocks\"][new_id] = block_op.get(\"content\", \"\")\n",
        "\n",
        "            elif operation == \"delete\":\n",
        "                block_id = block_op.get(\"id\")\n",
        "                if block_id in self.state[\"blocks\"]:\n",
        "                    del self.state[\"blocks\"][block_id]\n",
        "\n",
        "        # Update answer if provided\n",
        "        if answer is not None:\n",
        "            self.state[\"answer\"] = answer\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.state[\"status\"] != \"IN_PROGRESS\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1MKMppGhxpg"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    # Tools the agent can call\n",
        "    tools = {\"search\": SearchTool(), \"scrape\": ScrapTool()}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        task: str,\n",
        "        prompt: Prompt,\n",
        "        current_date: str = datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.prompt = prompt\n",
        "        self.current_date = current_date\n",
        "        self.tool_records = None\n",
        "        self.workspace = Workspace()\n",
        "        self.round = 0\n",
        "\n",
        "    async def run_tool(\n",
        "        self, tool_id: str, tool_input: str, context: str | None = None\n",
        "    ) -> str:\n",
        "        try:\n",
        "            assert tool_id in [\"search\", \"scrape\"], f\"Illegal tool: {tool_id}\"\n",
        "            tool = self.tools[tool_id]\n",
        "            result = await tool(tool_input, context)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run tool {e}\")\n",
        "            print(traceback.format_exc())\n",
        "            return f\"Tool execution failed: {e}\"\n",
        "\n",
        "    async def run(self, loop=True, max_rounds: int | None = None) -> Dict[str, Any]:\n",
        "        while True:\n",
        "            try:\n",
        "                # Rate limiting - 1 round per 20 seconds\n",
        "                await asyncio.sleep(20)\n",
        "                clear_output(wait=True)\n",
        "\n",
        "                response = await self.prompt.run(\n",
        "                    {\n",
        "                        \"current_date\": self.current_date,\n",
        "                        \"task\": self.task,\n",
        "                        \"workspace\": self.workspace.to_string(),\n",
        "                        \"tool_records\": self.tool_records,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                response = re.sub(\n",
        "                    r\"(?:<think>)?.*?</think>\", \"\", response, flags=re.DOTALL\n",
        "                )\n",
        "                response_json = extract_largest_json(response)\n",
        "                assert response_json\n",
        "\n",
        "                self.workspace.update_blocks(\n",
        "                    response_json.get(\"status_update\", \"IN_PROGRESS\"),\n",
        "                    response_json.get(\"memory_updates\"),\n",
        "                    response_json.get(\"answer\", None),\n",
        "                )\n",
        "\n",
        "                assert \"tool_calls\" in response_json\n",
        "\n",
        "                tool_calls = response_json[\"tool_calls\"]\n",
        "\n",
        "                tasks = [\n",
        "                    self.run_tool(call[\"tool\"], call[\"input\"], self.task)\n",
        "                    for call in tool_calls\n",
        "                ]\n",
        "\n",
        "                tool_outputs = await asyncio.gather(*tasks)\n",
        "\n",
        "                tool_records = [\n",
        "                    {**call, \"output\": output}\n",
        "                    for call, output in zip(tool_calls, tool_outputs)\n",
        "                ]\n",
        "\n",
        "                # Will be appended to the prompt in the next round\n",
        "                self.tool_records = tool_records\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in agent loop: {str(e)}\")\n",
        "                await asyncio.sleep(10)\n",
        "                continue\n",
        "\n",
        "            self.round += 1\n",
        "            if max_rounds and self.round > max_rounds:\n",
        "                break\n",
        "\n",
        "            if not loop:\n",
        "                break\n",
        "\n",
        "            if self.workspace.is_done():\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcWTZtl_OTHE"
      },
      "outputs": [],
      "source": [
        "prompt = Prompt(\"\"\"\n",
        "{% macro format_tool_results(tool_records) %}\n",
        "{% for to in tool_records %}\n",
        "Source {{ loop.index }}️: {{ to.tool }}: {{ to.input }}\n",
        "Result:\n",
        "```\n",
        "{{ to.output }}\n",
        "```\n",
        "{% endfor %}\n",
        "{% endmacro %}\n",
        "\n",
        "The date: `{{ current_date }}`.\n",
        "You are an information analysis and exploration agent that builds solutions through systematic investigation.\n",
        "\n",
        "## Investigation Cycle\n",
        "You operate in a continuous investigation cycle:\n",
        "\n",
        "1. Review current workspace (your memory blocks)\n",
        "2. Analyze new tool results (or initial task if first round)\n",
        "3. Update memory with new insights and track investigation progress\n",
        "4. Decide on next tools to call based on identified leads and information gaps\n",
        "5. Repeat until task completion\n",
        "\n",
        "## Memory Structure\n",
        "Your memory persists between investigation cycles and consists of:\n",
        "- **Status**: Always the first line, indicates if the task is IN_PROGRESS or DONE\n",
        "- **Memory**: A collection of discrete information blocks, each with a unique ID\n",
        "\n",
        "## Memory Block Usage\n",
        "- Each memory block has a unique ID in format <abc-123>content</abc-123>\n",
        "- Create separate blocks for distinct pieces of information:\n",
        "  * Discovered URLs (both explored and pending)\n",
        "  * Information gaps that need investigation\n",
        "  * Actions already taken (to avoid repetition)\n",
        "  * Promising leads for future exploration\n",
        "  * Key facts and findings\n",
        "  * Contradictions or inconsistencies found\n",
        "- Keep each block focused on a single idea or piece of information\n",
        "- Always cite sources when recording information from tool results\n",
        "- Use IDs to track and manage your knowledge (e.g., deleting outdated information)\n",
        "- Make sure to store sources (URLs) for the facts and findings you store\n",
        "\n",
        "## Lead Management\n",
        "- Since you can only make 3 tool calls per round, store promising leads for later\n",
        "- Create dedicated memory blocks for URLs to scrape later\n",
        "- Maintain blocks for potential search queries to explore in future rounds\n",
        "- Prioritize leads based on relevance to the task\n",
        "\n",
        "## Available Tools\n",
        "- **search**: Use for broad information gathering on new topics or concepts\n",
        "  * Example: {\"tool\": \"search\", \"input\": \"renewable energy statistics 2023\"}\n",
        "- **scrape**: Use for extracting specific details from discovered URLs\n",
        "  * Example: {\"tool\": \"scrape\", \"input\": \"https://example.com/energy-report\"}\n",
        "\n",
        "## Tool Usage Guidelines\n",
        "- **When to use search**: For new concepts, filling knowledge gaps, or exploring new directions\n",
        "- **When to use scrape**: For URLs discovered that likely contain detailed information\n",
        "- **Maximum 3 tool calls per round**\n",
        "- **Never repeat the exact same tool call**\n",
        "- **Always record valuable information from tool results in memory blocks**\n",
        "\n",
        "## Response Format\n",
        "You must respond with a valid JSON object containing:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"status_update\": \"IN_PROGRESS or DONE\",\n",
        "  \"memory_updates\": [\n",
        "    {\"operation\": \"add\", \"content\": \"New insight or lead to investigate\"},\n",
        "    {\"operation\": \"delete\", \"id\": \"abc-123\"}\n",
        "  ],\n",
        "  \"tool_calls\": [\n",
        "    {\"tool\": \"search\", \"input\": \"specific search query\"},\n",
        "    {\"tool\": \"scrape\", \"input\": \"https://discovered-url.com\"}\n",
        "  ],\n",
        "  \"answer\": \"Your final, comprehensive answer when status is DONE\"\n",
        "}\n",
        "```\n",
        "\n",
        "## Important Rules\n",
        "- The \"add\" operation creates a new memory block\n",
        "\tYou do not need to specify an ID, it will be added automatically by the system.\n",
        "- The \"delete\" operation requires the specific ID of the block to remove\n",
        "- Never invent or fabricate information - only use facts from your memory or tool results\n",
        "- Never make up URLs - only use URLs discovered through tool results\n",
        "- CRITICAL: Any information not recorded in your memory blocks will be lost in the next round\n",
        "  For example, if you find a potential webpage to scrap, you must store the URL and your intention\n",
        "  Example: `{\"operation\": \"add\", \"content\": \"Found relevant URL: https://... to scrape ...\"}`\n",
        "- IMPORTANT: Make sure to delete memory blocks that are no longer necessary\n",
        "- Set status to \"DONE\" only when you have fully addressed the task\n",
        "- Only include the \"answer\" field when status is \"DONE\"\n",
        "\n",
        "Task:\n",
        "```\n",
        "{{ task }}\n",
        "```\n",
        "\n",
        "Current workspace:\n",
        "```\n",
        "{{ workspace }}\n",
        "```\n",
        "\n",
        "Tool Results:\n",
        "{{ format_tool_results(tool_records) if tool_records else '... no previous tool results ...'}}\n",
        "\n",
        "IMPORTANT: Generate a valid JSON response following the format above.\n",
        "\n",
        "Think carefully about:\n",
        "- what information do you need to preserve\n",
        "- which tools to call next\n",
        "- how to build your answer systematically with focused memory blocks\n",
        "\n",
        "Do NOT rely on your internal knowledge (may be biased), aim to discover information using the tools!\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOF4XQnpAsTC"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6IpW4QGBKZ3"
      },
      "outputs": [],
      "source": [
        "task = \"\"\"\n",
        "帮我找一下windows端的轻量级浏览器，轻量级是指占用低，内存小，加载快，还有最新的一些ai浏览器，列出一个中文表格\n",
        "\"\"\"\n",
        "\n",
        "agent = Agent(task=task, prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iteration Zero\n",
        "\n",
        "Before we run the model, we have an empty state:"
      ],
      "metadata": {
        "id": "lPW2FrqKCkpY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6E_kK2V_6wy"
      },
      "outputs": [],
      "source": [
        "print(agent.workspace.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iteration One"
      ],
      "metadata": {
        "id": "RX_Cacs6Cr0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBP0csl1dYmN"
      },
      "outputs": [],
      "source": [
        "await agent.run(loop=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGyMCgkg_6wz"
      },
      "outputs": [],
      "source": [
        "agent.workspace.to_string()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iteration Two"
      ],
      "metadata": {
        "id": "DCU8vWV-DPXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0yt1j33BkDR"
      },
      "outputs": [],
      "source": [
        "await agent.run(loop=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.workspace.to_string()"
      ],
      "metadata": {
        "id": "XONEtaNILAhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iteration Three"
      ],
      "metadata": {
        "id": "u9lKhrCsKzcy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE4eYaRa_6wz"
      },
      "outputs": [],
      "source": [
        "await agent.run(loop=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfP90yg6_6w0"
      },
      "outputs": [],
      "source": [
        "agent.workspace.to_string()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### And So On..."
      ],
      "metadata": {
        "id": "ObQb2ghcLKOf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF_e8KYM_6w0"
      },
      "outputs": [],
      "source": [
        "await agent.run(loop=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6FO2HHDqDeyp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}